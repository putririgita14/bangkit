{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV5OoaSWnAV676HOHy88P4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putririgita14/bangkit/blob/main/Problem_B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZl3YIWTdHYc",
        "outputId": "a8344c6f-9f0c-450a-cbab-f72d8b236844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "56/56 - 13s - loss: 1.6575 - accuracy: 0.2236 - val_loss: 1.6049 - val_accuracy: 0.2270 - 13s/epoch - 230ms/step\n",
            "Epoch 2/100\n",
            "56/56 - 3s - loss: 1.5992 - accuracy: 0.2354 - val_loss: 1.5656 - val_accuracy: 0.3079 - 3s/epoch - 48ms/step\n",
            "Epoch 3/100\n",
            "56/56 - 2s - loss: 1.3804 - accuracy: 0.4185 - val_loss: 1.1000 - val_accuracy: 0.5506 - 2s/epoch - 35ms/step\n",
            "Epoch 4/100\n",
            "56/56 - 1s - loss: 0.8536 - accuracy: 0.6202 - val_loss: 0.7898 - val_accuracy: 0.6517 - 1s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "56/56 - 1s - loss: 0.5915 - accuracy: 0.7674 - val_loss: 0.5441 - val_accuracy: 0.8112 - 759ms/epoch - 14ms/step\n",
            "Epoch 6/100\n",
            "56/56 - 1s - loss: 0.3444 - accuracy: 0.8843 - val_loss: 0.5027 - val_accuracy: 0.8337 - 895ms/epoch - 16ms/step\n",
            "Epoch 7/100\n",
            "56/56 - 1s - loss: 0.2091 - accuracy: 0.9365 - val_loss: 0.4117 - val_accuracy: 0.8876 - 1s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "56/56 - 2s - loss: 0.1505 - accuracy: 0.9635 - val_loss: 0.3467 - val_accuracy: 0.8876 - 2s/epoch - 29ms/step\n",
            "Epoch 9/100\n",
            "56/56 - 0s - loss: 0.1062 - accuracy: 0.9713 - val_loss: 0.4194 - val_accuracy: 0.8899 - 471ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "56/56 - 0s - loss: 0.0898 - accuracy: 0.9742 - val_loss: 0.3659 - val_accuracy: 0.8966 - 494ms/epoch - 9ms/step\n",
            "Epoch 11/100\n",
            "56/56 - 0s - loss: 0.0671 - accuracy: 0.9837 - val_loss: 0.3673 - val_accuracy: 0.8966 - 469ms/epoch - 8ms/step\n",
            "Epoch 12/100\n",
            "56/56 - 1s - loss: 0.0896 - accuracy: 0.9764 - val_loss: 0.4382 - val_accuracy: 0.8944 - 903ms/epoch - 16ms/step\n",
            "Epoch 13/100\n",
            "56/56 - 0s - loss: 0.0476 - accuracy: 0.9899 - val_loss: 0.3431 - val_accuracy: 0.9169 - 498ms/epoch - 9ms/step\n",
            "Epoch 14/100\n",
            "56/56 - 0s - loss: 0.0550 - accuracy: 0.9871 - val_loss: 0.4355 - val_accuracy: 0.9034 - 464ms/epoch - 8ms/step\n",
            "Epoch 15/100\n",
            "56/56 - 0s - loss: 0.0540 - accuracy: 0.9843 - val_loss: 0.3189 - val_accuracy: 0.9191 - 493ms/epoch - 9ms/step\n",
            "Epoch 16/100\n",
            "56/56 - 1s - loss: 0.0299 - accuracy: 0.9955 - val_loss: 0.3486 - val_accuracy: 0.9236 - 633ms/epoch - 11ms/step\n",
            "Epoch 17/100\n",
            "56/56 - 1s - loss: 0.0335 - accuracy: 0.9927 - val_loss: 0.3299 - val_accuracy: 0.9213 - 525ms/epoch - 9ms/step\n",
            "Epoch 18/100\n",
            "56/56 - 0s - loss: 0.0264 - accuracy: 0.9944 - val_loss: 0.3281 - val_accuracy: 0.9258 - 330ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "56/56 - 0s - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.3891 - val_accuracy: 0.9191 - 477ms/epoch - 9ms/step\n",
            "Epoch 20/100\n",
            "56/56 - 1s - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.3801 - val_accuracy: 0.9146 - 765ms/epoch - 14ms/step\n",
            "Epoch 21/100\n",
            "56/56 - 0s - loss: 0.0342 - accuracy: 0.9927 - val_loss: 0.3282 - val_accuracy: 0.9191 - 361ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "56/56 - 0s - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.3833 - val_accuracy: 0.9169 - 468ms/epoch - 8ms/step\n",
            "Epoch 23/100\n",
            "56/56 - 0s - loss: 0.0164 - accuracy: 0.9961 - val_loss: 0.3438 - val_accuracy: 0.9371 - 350ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "56/56 - 1s - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.3554 - val_accuracy: 0.9326 - 518ms/epoch - 9ms/step\n",
            "Epoch 25/100\n",
            "56/56 - 0s - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.4227 - val_accuracy: 0.8944 - 483ms/epoch - 9ms/step\n",
            "Epoch 26/100\n",
            "56/56 - 0s - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.3324 - val_accuracy: 0.9348 - 485ms/epoch - 9ms/step\n",
            "Epoch 27/100\n",
            "56/56 - 1s - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.4250 - val_accuracy: 0.9213 - 653ms/epoch - 12ms/step\n",
            "Epoch 28/100\n",
            "56/56 - 1s - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.4018 - val_accuracy: 0.9213 - 745ms/epoch - 13ms/step\n",
            "Epoch 29/100\n",
            "56/56 - 0s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.4035 - val_accuracy: 0.9213 - 464ms/epoch - 8ms/step\n",
            "Epoch 30/100\n",
            "56/56 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9213 - 750ms/epoch - 13ms/step\n",
            "Epoch 31/100\n",
            "56/56 - 0s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4231 - val_accuracy: 0.9213 - 474ms/epoch - 8ms/step\n",
            "Epoch 32/100\n",
            "56/56 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9258 - 842ms/epoch - 15ms/step\n",
            "Epoch 33/100\n",
            "56/56 - 0s - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.5268 - val_accuracy: 0.9034 - 443ms/epoch - 8ms/step\n",
            "Epoch 34/100\n",
            "56/56 - 1s - loss: 0.0569 - accuracy: 0.9854 - val_loss: 0.4406 - val_accuracy: 0.9146 - 536ms/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "56/56 - 0s - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.4345 - val_accuracy: 0.9124 - 360ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "56/56 - 0s - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.3743 - val_accuracy: 0.9169 - 500ms/epoch - 9ms/step\n",
            "Epoch 37/100\n",
            "56/56 - 1s - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.3587 - val_accuracy: 0.9303 - 629ms/epoch - 11ms/step\n",
            "Epoch 38/100\n",
            "56/56 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9124 - 486ms/epoch - 9ms/step\n",
            "Epoch 39/100\n",
            "56/56 - 1s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.4335 - val_accuracy: 0.9326 - 628ms/epoch - 11ms/step\n",
            "Epoch 40/100\n",
            "56/56 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9258 - 507ms/epoch - 9ms/step\n",
            "Epoch 41/100\n",
            "56/56 - 0s - loss: 0.0658 - accuracy: 0.9831 - val_loss: 0.3042 - val_accuracy: 0.9213 - 467ms/epoch - 8ms/step\n",
            "Epoch 42/100\n",
            "56/56 - 0s - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.3880 - val_accuracy: 0.9124 - 352ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "56/56 - 0s - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.4020 - val_accuracy: 0.9124 - 351ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "56/56 - 0s - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.3641 - val_accuracy: 0.9258 - 315ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "56/56 - 0s - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.3828 - val_accuracy: 0.9213 - 476ms/epoch - 9ms/step\n",
            "Epoch 46/100\n",
            "56/56 - 0s - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3563 - val_accuracy: 0.9326 - 470ms/epoch - 8ms/step\n",
            "Epoch 47/100\n",
            "56/56 - 0s - loss: 9.3019e-04 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9303 - 468ms/epoch - 8ms/step\n",
            "Epoch 48/100\n",
            "56/56 - 0s - loss: 7.2561e-04 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9281 - 333ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "56/56 - 0s - loss: 6.4313e-04 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9281 - 336ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "56/56 - 0s - loss: 5.6404e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9303 - 471ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "56/56 - 0s - loss: 7.1899e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9281 - 340ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "56/56 - 1s - loss: 7.2417e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9258 - 509ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "56/56 - 0s - loss: 4.3007e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9258 - 337ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "56/56 - 1s - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.5027 - val_accuracy: 0.8899 - 540ms/epoch - 10ms/step\n",
            "Epoch 55/100\n",
            "56/56 - 1s - loss: 0.0454 - accuracy: 0.9888 - val_loss: 0.4266 - val_accuracy: 0.9169 - 711ms/epoch - 13ms/step\n",
            "Epoch 56/100\n",
            "56/56 - 1s - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.4476 - val_accuracy: 0.9258 - 711ms/epoch - 13ms/step\n",
            "Epoch 57/100\n",
            "56/56 - 1s - loss: 9.2782e-04 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9303 - 795ms/epoch - 14ms/step\n",
            "Epoch 58/100\n",
            "56/56 - 0s - loss: 0.0659 - accuracy: 0.9865 - val_loss: 0.3764 - val_accuracy: 0.9169 - 466ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "56/56 - 0s - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.3856 - val_accuracy: 0.9371 - 335ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "56/56 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9236 - 638ms/epoch - 11ms/step\n",
            "Epoch 61/100\n",
            "56/56 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9326 - 490ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "56/56 - 0s - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.5666 - val_accuracy: 0.9011 - 474ms/epoch - 8ms/step\n",
            "Epoch 63/100\n",
            "56/56 - 0s - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.5069 - val_accuracy: 0.9124 - 467ms/epoch - 8ms/step\n",
            "Epoch 64/100\n",
            "56/56 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9169 - 361ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "56/56 - 0s - loss: 0.0447 - accuracy: 0.9899 - val_loss: 0.3827 - val_accuracy: 0.9213 - 352ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "56/56 - 1s - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.3581 - val_accuracy: 0.9326 - 510ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "56/56 - 0s - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.4155 - val_accuracy: 0.9146 - 341ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "56/56 - 0s - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.4203 - val_accuracy: 0.9258 - 323ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "56/56 - 0s - loss: 8.4731e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9258 - 371ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "56/56 - 0s - loss: 6.8090e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9258 - 320ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "56/56 - 0s - loss: 6.3462e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9236 - 338ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "56/56 - 0s - loss: 5.1173e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9258 - 332ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "56/56 - 0s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4212 - val_accuracy: 0.9281 - 474ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "56/56 - 0s - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.5898 - val_accuracy: 0.9034 - 327ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "56/56 - 0s - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.4766 - val_accuracy: 0.9079 - 479ms/epoch - 9ms/step\n",
            "Epoch 76/100\n",
            "56/56 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9236 - 345ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "56/56 - 0s - loss: 5.8824e-04 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9191 - 433ms/epoch - 8ms/step\n",
            "Epoch 78/100\n",
            "56/56 - 0s - loss: 4.7361e-04 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9146 - 336ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "56/56 - 0s - loss: 3.6769e-04 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9146 - 486ms/epoch - 9ms/step\n",
            "Epoch 80/100\n",
            "56/56 - 0s - loss: 4.1661e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9124 - 330ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "56/56 - 0s - loss: 2.9337e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9124 - 487ms/epoch - 9ms/step\n",
            "Epoch 82/100\n",
            "56/56 - 1s - loss: 3.2000e-04 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.9213 - 553ms/epoch - 10ms/step\n",
            "Epoch 83/100\n",
            "56/56 - 0s - loss: 2.5290e-04 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.9169 - 492ms/epoch - 9ms/step\n",
            "Epoch 84/100\n",
            "56/56 - 0s - loss: 2.0975e-04 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.9169 - 464ms/epoch - 8ms/step\n",
            "Epoch 85/100\n",
            "56/56 - 0s - loss: 2.3392e-04 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.9191 - 464ms/epoch - 8ms/step\n",
            "Epoch 86/100\n",
            "56/56 - 1s - loss: 2.1472e-04 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.9191 - 982ms/epoch - 18ms/step\n",
            "Epoch 87/100\n",
            "56/56 - 1s - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.9169 - 804ms/epoch - 14ms/step\n",
            "Epoch 88/100\n",
            "56/56 - 0s - loss: 1.6422e-04 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.9169 - 491ms/epoch - 9ms/step\n",
            "Epoch 89/100\n",
            "56/56 - 0s - loss: 2.4055e-04 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.9101 - 370ms/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "56/56 - 0s - loss: 1.4924e-04 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.9124 - 327ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "56/56 - 0s - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.6377 - val_accuracy: 0.9101 - 368ms/epoch - 7ms/step\n",
            "Epoch 92/100\n",
            "56/56 - 0s - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5860 - val_accuracy: 0.9258 - 354ms/epoch - 6ms/step\n",
            "Epoch 93/100\n",
            "56/56 - 0s - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.5947 - val_accuracy: 0.9169 - 353ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "56/56 - 0s - loss: 0.0259 - accuracy: 0.9949 - val_loss: 0.4758 - val_accuracy: 0.9146 - 329ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "56/56 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.9169 - 328ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "56/56 - 0s - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.4453 - val_accuracy: 0.9213 - 338ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "56/56 - 0s - loss: 3.7092e-04 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9191 - 337ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "56/56 - 0s - loss: 2.7784e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9169 - 320ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "56/56 - 0s - loss: 2.9769e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9146 - 474ms/epoch - 8ms/step\n",
            "Epoch 100/100\n",
            "56/56 - 0s - loss: 2.0500e-04 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9146 - 346ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================================================\n",
        "# PROBLEM B4\n",
        "#\n",
        "# Build and train a classifier for the BBC-text dataset.\n",
        "# This is a multiclass classification problem.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 91%\n",
        "# ===================================================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def solution_B4():\n",
        "    bbc = pd.read_csv('https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or you can not pass this test\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_portion = .8\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    # Using \"shuffle=False\"\n",
        "    labels = bbc[\"category\"].values.tolist()\n",
        "    sentences = bbc[\"text\"].values.tolist()\n",
        "\n",
        "    training_size = int(len(sentences) * training_portion)\n",
        "    training_sentences = sentences[:training_size]\n",
        "    training_labels = labels[:training_size]\n",
        "    validation_sentences = sentences[training_size:]\n",
        "    validation_labels = labels[training_size:]\n",
        "\n",
        "    # Fit your tokenizer with training data\n",
        "    tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    training_padded_sequences = pad_sequences(training_sequences, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
        "    validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "    validation_padded_sequences = pad_sequences(validation_sequences, padding=padding_type, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "    label_tokenizer = Tokenizer()\n",
        "    label_tokenizer.fit_on_texts(labels)\n",
        "    label_word_index = label_tokenizer.word_index\n",
        "    training_label_sequences = label_tokenizer.texts_to_sequences(training_labels)\n",
        "    training_label_sequences = np.array(training_label_sequences)\n",
        "    validation_label_sequences = label_tokenizer.texts_to_sequences(validation_labels)\n",
        "    validation_label_sequences = np.array(validation_label_sequences)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "        tf.keras.layers.LSTM(64),\n",
        "        tf.keras.layers.Dense(6, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Make sure you are using \"sparse_categorical_crossentropy\" as a loss fuction\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "    model.fit(\n",
        "        training_padded_sequences,\n",
        "        training_label_sequences,\n",
        "        epochs=100,\n",
        "        validation_data=(\n",
        "            validation_padded_sequences,\n",
        "            validation_label_sequences),\n",
        "        verbose=2)\n",
        "\n",
        "    return model\n",
        "\n",
        "    # The code below is to save your model as a .h5 file.\n",
        "    # It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_B4()\n",
        "    model.save(\"model_B4.h5\")\n"
      ]
    }
  ]
}