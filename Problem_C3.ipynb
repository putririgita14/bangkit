{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXBInNFzsXohS2IHr6xGN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putririgita14/bangkit/blob/main/Problem_C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw2NzUl3OU0j",
        "outputId": "3e66fcae-69fc-4a04-b78e-f92d7b818512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 24s 477ms/step - loss: 1.1307 - accuracy: 0.5050 - val_loss: 0.6718 - val_accuracy: 0.5320\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.6815 - accuracy: 0.5600 - val_loss: 0.6581 - val_accuracy: 0.6020\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.6571 - accuracy: 0.5965 - val_loss: 0.6638 - val_accuracy: 0.5910\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 15s 474ms/step - loss: 0.6386 - accuracy: 0.6500 - val_loss: 0.6205 - val_accuracy: 0.6700\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 16s 512ms/step - loss: 0.6103 - accuracy: 0.6775 - val_loss: 0.6329 - val_accuracy: 0.6360\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.5897 - accuracy: 0.6880 - val_loss: 0.5832 - val_accuracy: 0.6790\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 0.5899 - accuracy: 0.6840 - val_loss: 0.6242 - val_accuracy: 0.6620\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 0.5842 - accuracy: 0.6960 - val_loss: 0.5708 - val_accuracy: 0.6900\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 0.5592 - accuracy: 0.7205 - val_loss: 0.5835 - val_accuracy: 0.6660\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 0.5535 - accuracy: 0.7185 - val_loss: 0.5652 - val_accuracy: 0.7130\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.5320 - accuracy: 0.7315 - val_loss: 0.5677 - val_accuracy: 0.7080\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 0.5316 - accuracy: 0.7375 - val_loss: 0.5607 - val_accuracy: 0.7120\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 0.5219 - accuracy: 0.7355 - val_loss: 0.6237 - val_accuracy: 0.6980\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 0.5488 - accuracy: 0.7260 - val_loss: 0.5586 - val_accuracy: 0.7070\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 0.5142 - accuracy: 0.7365 - val_loss: 0.5401 - val_accuracy: 0.7200\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.5340 - accuracy: 0.7280 - val_loss: 0.5680 - val_accuracy: 0.7170\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7555\n",
            "Target telah tercapai, stop training!\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 0.5042 - accuracy: 0.7555 - val_loss: 0.5588 - val_accuracy: 0.7370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================================================\n",
        "# PROBLEM C3\n",
        "#\n",
        "# Build a CNN based classifier for Cats vs Dogs dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "#\n",
        "# Desired accuracy and validation_accuracy > 72%\n",
        "# ========================================================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.73 and logs.get('val_accuracy')>0.73):\n",
        "            print(\"\\nTarget telah tercapai, stop training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def solution_C3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n",
        "    local_file = 'cats_and_dogs.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    BASE_DIR = 'data/cats_and_dogs_filtered'\n",
        "    train_dir = os.path.join(BASE_DIR, 'train')\n",
        "    validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "    train_datagen =  ImageDataGenerator(rescale=1. / 255, horizontal_flip=True, zoom_range=0.2, shear_range=0.1, # YOUR CODE HERE\n",
        "                                       rotation_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "    # Make sure you used \"binary\"\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=64,\n",
        "        class_mode='binary')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        epochs=30,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[myCallback()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C3()\n",
        "    model.save(\"model_C3.h5\")\n"
      ]
    }
  ]
}