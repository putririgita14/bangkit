{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9CtlVKKHOakGfie1z/QA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putririgita14/bangkit/blob/main/Problem_C5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcS2qzVvT6f5",
        "outputId": "2f5937d7-4dd0-4fde-9a9c-644f9c7c36a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-55977b337a42>:55: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df = pd.read_csv('household_power_consumption.csv', sep=',',\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "   1349/Unknown - 54s 32ms/step - loss: 0.0479 - mae: 0.0479\n",
            "Target telah tercapai!\n",
            "1349/1349 [==============================] - 74s 47ms/step - loss: 0.0479 - mae: 0.0479 - val_loss: 0.0482 - val_mae: 0.0482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================================\n",
        "# PROBLEM C5\n",
        "#\n",
        "# Build and train a neural network to predict time indexed variables of\n",
        "# the multivariate house hold electric power consumption time series dataset.\n",
        "# Using a window of past 24 observations of the 7 variables, the model\n",
        "# should be trained to predict the next 24 observations of the 7 variables.\n",
        "# Use MAE as the metrics of your neural network model.\n",
        "# We provided code for normalizing the data. Please do not change the code.\n",
        "# Do not use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is downloaded from https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption\n",
        "#\n",
        "# Desired MAE < 0.1 on the normalized dataset.\n",
        "# ============================================================================================\n",
        "\n",
        "import urllib\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# This function downloads and extracts the dataset to the directory that contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change the URL)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/household_power.zip'\n",
        "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "    with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "\n",
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(n_past + n_future))\n",
        "    dataset =dataset.shuffle(1000)\n",
        "    dataset = dataset.map(lambda window: (window[:-n_future], window[-n_future:, :1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def solution_C5():\n",
        "    # Downloads and extracts the dataset to the directory that contains this file.\n",
        "    download_and_extract_data()\n",
        "    # Reads the dataset from the csv.\n",
        "    df = pd.read_csv('household_power_consumption.csv', sep=',',\n",
        "                     infer_datetime_format=True, index_col='datetime', header=0)\n",
        "\n",
        "    # Number of features in the dataset. We use all features as predictors to\n",
        "    # predict all features at future time steps.\n",
        "    N_FEATURES = 7\n",
        "\n",
        "    # Normalizes the data\n",
        "    # DO NOT CHANGE THIS\n",
        "    data = df.values\n",
        "    split_time = int(len(data) * 0.5)\n",
        "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "\n",
        "    # Splits the data into training and validation sets.\n",
        "    x_train = data[:split_time]\n",
        "    x_valid = data[split_time:]\n",
        "\n",
        "    # DO NOT CHANGE THIS\n",
        "    BATCH_SIZE = 32\n",
        "    N_PAST = 24 # Number of past time steps based on which future observations should be predicted\n",
        "    N_FUTURE = 24  # Number of future time steps which are to be predicted.\n",
        "    SHIFT = 1  # By how many positions the window slides to create a new window of observations.\n",
        "\n",
        "    # Code to create windowed train and validation datasets.\n",
        "    # Complete the code in windowed_dataset.\n",
        "    train_set = windowed_dataset(x_train, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT)\n",
        "    valid_set = windowed_dataset(x_valid, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT)\n",
        "\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            if(logs.get('mae')<0.09 and logs.get('val_mae')<0.09):\n",
        "                print(\"\\nTarget telah tercapai!\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "    # Code to define your model.\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Whatever your first layer is, the input shape will be (N_PAST = 24, N_FEATURES = 7)\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True, input_shape=[N_PAST, N_FEATURES]),\n",
        "        tf.keras.layers.LSTM(32),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(N_FUTURE),\n",
        "    ])\n",
        "\n",
        "    # Code to train and compile the model\n",
        "    model.compile(loss='mae', metrics=['mae'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "    model.fit(train_set, epochs=50, validation_data=valid_set, callbacks=[myCallback()], verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C5()\n",
        "    model.save(\"model_C5.h5\")"
      ]
    }
  ]
}